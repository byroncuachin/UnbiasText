{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify\n",
    "from nltk.stem import PorterStemmer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# # Preprocessing functions\n",
    "# add space before punctuations\n",
    "\n",
    "app = Flask(__name__)\n",
    "explainer = LimeTextExplainer(class_names=['female', 'male'])\n",
    "stemmer = PorterStemmer()\n",
    "def add_space_before(text):\n",
    "    # regular expression to add space before punctuations\n",
    "    processed_text = re.sub(r'([^\\s\\w])', r' \\1', text)\n",
    "    return processed_text\n",
    "\n",
    "# remove gendered pronounds, names, stop words, and apply stemming\n",
    "def removeUnnecessaryWords(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    result = \" \".join([\n",
    "        \"\" if (\n",
    "            token.pos_ == \"PRON\" and token.lemma_ not in [\"I\", \"you\"]\n",
    "        ) or (\n",
    "            token.ent_type_ == \"PERSON\" or token.text.lower() in [\"woman\", \"women\", \"man\", \"men\", \"he\", \"she\", \"him\", \"her\"]\n",
    "        ) or (\n",
    "            token.text.lower() in STOP_WORDS\n",
    "        ) else stemmer.stem(token.lemma_) for token in doc])\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (file:///Users/byroncuachin/.cache/huggingface/datasets/pranjali97___parquet/pranjali97--Bias-detection-combined-13b07b91e7f5086e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mpranjali97/Bias-detection-combined\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1808\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1809\u001b[0m )\n\u001b[0;32m-> 1810\u001b[0m ds \u001b[39m=\u001b[39m builder_instance\u001b[39m.\u001b[39mas_dataset(split\u001b[39m=\u001b[39msplit, verification_mode\u001b[39m=\u001b[39mverification_mode, in_memory\u001b[39m=\u001b[39mkeep_in_memory)\n\u001b[1;32m   1811\u001b[0m \u001b[39m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1105\u001b[0m is_local \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m is_remote_filesystem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_local:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading a dataset cached in a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dir):\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: could not find data in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dir\u001b[39m}\u001b[39;00m\u001b[39m. Please make sure to call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbuilder.download_and_prepare(), or use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"pranjali97/Bias-detection-combined\")\n",
    "# train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# 0 is liberal; 1 is conservative\n",
    "\n",
    "# dataset[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# preprocess training and testing data\n",
    "dataset[\"train\"][\"text\"][:38200] = dataset['sentence_text'].apply(add_space_before).apply(removeUnnecessaryWords)\n",
    "dataset[\"validation\"][\"text\"][:38200] = dataset['sentence_text'].apply(add_space_before).apply(removeUnnecessaryWords)\n",
    "\n",
    "trainTexts = vectorizer.fit_transform(dataset[\"train\"][\"text\"][:38200]) # 20000\n",
    "testTexts = vectorizer.transform(dataset[\"validation\"][\"text\"][:38200]) # 20000\n",
    "\n",
    "X_train = pd.DataFrame(trainTexts.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_test = pd.DataFrame(testTexts.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "y_train = dataset[\"train\"][\"label\"][:38200] # 20000\n",
    "y_test = dataset[\"validation\"][\"label\"][:38200] # 20000\n",
    "\n",
    "# train model\n",
    "# model = LinearSVC()\n",
    "# model.fit(xTrain, yTrain)\n",
    "\n",
    "# model = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "# model.fit(xTrain, yTrain)\n",
    "\n",
    "# with open('./savedModels/randomForestPOLITICAL.pkl', 'wb') as model_file:\n",
    "#     pickle.dump((model, vectorizer), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(rf, X_test, y_test, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "# scores = evaluate_model(rf)\n",
    "# print('Score: {:.4f}'.format(scores.mean()))\n",
    "modelrf = rf.fit(X_train, y_train)\n",
    "# accuracy\n",
    "predrf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelSVC = LinearSVC()\n",
    "modelSVC.fit(X_train, y_train)\n",
    "predSVC = modelSVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCC = CalibratedClassifierCV(modelSVC, method='sigmoid', cv='prefit')\n",
    "# modelCC = CalibratedClassifierCV(modelSVC, method='isotonic', cv='prefit')\n",
    "modelCC.fit(X_train, y_train)\n",
    "predCC = modelCC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSGD = SGDClassifier()\n",
    "modelSGD.fit(X_train, y_train)\n",
    "predSGD = modelSGD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_cgpt = [('pca', PCA(n_components=7)), ('m', LogisticRegression())]\n",
    "# modelPip = Pipeline(steps=steps_cgpt)\n",
    "# modelPip.fit(X_train, y_train)\n",
    "# predPip = modelPip.predict(X_test)\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# clf1 = DecisionTreeClassifier(max_features=1, random_state=0)\n",
    "# clf2 = BaggingClassifier(max_features=4, random_state=0)\n",
    "# clf3 = RandomForestClassifier(max_features=1, random_state=0)\n",
    "# clf4 = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "# eclf1 = VotingClassifier(estimators=[('dt', clf1), ('bdt', clf2), ('rf', clf3), ('ab', clf4)], voting='hard')\n",
    "# eclf1 = eclf1.fit(X_train, y_train)\n",
    "# predEoE = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./savedModels/politicalCCModel.pkl', 'wb') as model_file:\n",
    "    pickle.dump((modelCC, vectorizer), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :\n",
      "Liberal:  0.2171458321821546\n",
      "Conservative:  0.7828541678178453\n",
      "Predicted:  0\n",
      "Actual: Liberal\n",
      "Top words for text response 1:\n",
      "Liberal words:  [('know', 0.06178258365327984), ('Liberals', 0.04457119594102481), ('s', 0.0001855333609870643)]\n",
      "Conservative words:  [('what', -0.028324825670516546), ('up', -0.015267124161473442)]\n",
      "\n",
      "2 :\n",
      "Liberal:  0.12405569905638592\n",
      "Conservative:  0.8759443009436141\n",
      "Predicted:  0\n",
      "Actual: Conservative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for text response 2:\n",
      "Liberal words:  [('illegal', 0.026801596999851615), ('be', 0.005592652404028004)]\n",
      "Conservative words:  [('should', -0.05076371417896263), ('Abortion', -0.011994565450412829)]\n",
      "\n",
      "3 :\n",
      "Liberal:  0.23577589584118494\n",
      "Conservative:  0.764224104158815\n",
      "Predicted:  0\n",
      "Actual: Conservative\n",
      "Top words for text response 3:\n",
      "Liberal words:  [('Trump', 0.1325628201320244), ('the', 0.011983751155257379)]\n",
      "Conservative words:  [('win', -0.036485855641067086), ('for', -0.02883393099368923)]\n",
      "\n",
      "4 :\n",
      "Liberal:  0.047350725522956\n",
      "Conservative:  0.952649274477044\n",
      "Predicted:  0\n",
      "Actual: Liberal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for text response 4:\n",
      "Liberal words:  [('debt', 0.03814176216971023), ('biden', 0.030335492173116537), ('more', 0.016434506211342598), ('no', 0.0009073048822183146)]\n",
      "Conservative words:  [('Thanks', -0.09750281630195293), ('yessss', -0.07626009899251267), ('student', -0.03361284136996062)]\n",
      "\n",
      "5 :\n",
      "Liberal:  0.6961870586877865\n",
      "Conservative:  0.3038129413122135\n",
      "Predicted:  1\n",
      "Actual: Conservative\n",
      "Top words for text response 5:\n",
      "Liberal words:  [('old', 0.42851345706374877), ('Trump', 0.17523627640184852), ('biden', 0.07951313932187316), ('even', 0.0430581738172989)]\n",
      "Conservative words:  [('is', -0.14337228564587537), ('if', -0.05851423185319642), ('too', -0.006446528749257277)]\n",
      "\n",
      "6 :\n",
      "Liberal:  0.5200623903842099\n",
      "Conservative:  0.47993760961579013\n",
      "Predicted:  1\n",
      "Actual: Conservative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for text response 6:\n",
      "Liberal words:  [('roe', 0.42762928942585116), ('wade', 0.19716041658461897), ('v', 0.0008881359202391353)]\n",
      "Conservative words:  [('thank', -0.14890361440256056), ('is', -0.07217663604826363), ('god', -0.05296700563745656), ('gone', -0.013371288807439362)]\n",
      "\n",
      "7 :\n",
      "Liberal:  0.11455882656509836\n",
      "Conservative:  0.8854411734349017\n",
      "Predicted:  0\n",
      "Actual: Conservative\n",
      "Top words for text response 7:\n",
      "Liberal words:  []\n",
      "Conservative words:  [('MAGA', -0.014966708224694886)]\n",
      "\n",
      "8 :\n",
      "Liberal:  0.24087670583109633\n",
      "Conservative:  0.7591232941689037\n",
      "Predicted:  0\n",
      "Actual: Liberal\n",
      "Top words for text response 8:\n",
      "Liberal words:  [('years', 0.08685698561826047), ('been', 0.08348576568408557), ('biden', 0.06662044017306537), ('has', 0.04820235206103565), ('well', 0.029210379523304294), ('couple', 0.028692285610274988), ('of', 0.018747146029139298), ('the', 0.010179785037913105)]\n",
      "Conservative words:  [('past', -0.20471104069301754), ('doing', -0.10682224141552635)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=[\"conservative\", \"liberal\"])\n",
    "stemmer = PorterStemmer()\n",
    "text= ['''Liberals know what's up''',\n",
    "            '''Abortion should be illegal.''',\n",
    "            '''Trump for the win''',\n",
    "            '''no more student debt yessss. Thanks biden''',\n",
    "            '''even if Trump is old, biden is too old''',\n",
    "            '''thank god roe v wade is gone''',\n",
    "            '''MAGA. MAGA. MAGA''',\n",
    "            '''biden has been doing well the past couple of years''']\n",
    "yActual = [1, 0, 0, 1, 0, 0, 0, 1] # 0 is conservative (similar to female); 1 is liberal (similar to male)\n",
    "\n",
    "vectorizedText = vectorizer.transform(text)\n",
    "textsTransformed = pd.DataFrame(vectorizedText.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "predProb = modelCC.predict_proba(textsTransformed)\n",
    "pred = modelCC.predict(textsTransformed)\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=['Conservative', 'Liberal'])\n",
    "for i in range(len(pred)):\n",
    "    print(i + 1, \":\")\n",
    "    print(\"Liberal: \", predProb[i][1])\n",
    "    print(\"Conservative: \", predProb[i][0])\n",
    "    print(\"Predicted: \", pred[i])\n",
    "    if(yActual[i] == 0):\n",
    "        print(\"Actual: Conservative\")\n",
    "    else:\n",
    "        print(\"Actual: Liberal\")\n",
    "        \n",
    "    vectorized_text = vectorizer.transform([text[i]])\n",
    "    predict_function = lambda x: modelCC.predict_proba(vectorizer.transform(x))\n",
    "    explanation = explainer.explain_instance(text[i], predict_function, num_features=20)\n",
    "    top_words_lime = explanation.as_list()\n",
    "    print(f\"Top words for text response {i + 1}:\")\n",
    "    liberalWords = []\n",
    "    conservativeWords = []\n",
    "    for word, score in top_words_lime:\n",
    "        if score > 0:\n",
    "            liberalWords.append((word, score))\n",
    "        else:\n",
    "            conservativeWords.append((word, score))\n",
    "    print(\"Liberal words: \", liberalWords)\n",
    "    print(\"Conservative words: \", conservativeWords)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal Percentage:  0 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('know', 0.061), ('Liberals', 0.044)]\n",
      "Conservative Words:  [('what', -0.028), ('up', -0.015)]\n",
      "Original Liberal Words:  ['know', 'Liberals']\n",
      "Original Conservative Words:  ['up']\n",
      "Liberal Percentage:  1 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('illegal', 0.027), ('be', 0.005)]\n",
      "Conservative Words:  [('should', -0.051), ('Abortion', -0.012)]\n",
      "Original Liberal Words:  ['be']\n",
      "Original Conservative Words:  ['should', 'Abortion']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal Percentage:  2 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('Trump', 0.132), ('the', 0.012)]\n",
      "Conservative Words:  [('win', -0.037), ('for', -0.029)]\n",
      "Original Liberal Words:  ['Trump', 'the']\n",
      "Original Conservative Words:  ['win', 'for']\n",
      "Liberal Percentage:  3 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('debt', 0.038), ('biden', 0.031), ('more', 0.016)]\n",
      "Conservative Words:  [('Thanks', -0.097), ('yessss', -0.077), ('student', -0.033)]\n",
      "Original Liberal Words:  ['debt', 'biden', 'more']\n",
      "Original Conservative Words:  ['Thanks', 'student']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal Percentage:  4 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('old', 0.429), ('Trump', 0.172), ('biden', 0.079)]\n",
      "Conservative Words:  [('is', -0.142), ('if', -0.057), ('too', -0.007)]\n",
      "Original Liberal Words:  ['old', 'Trump', 'biden']\n",
      "Original Conservative Words:  ['is', 'if', 'too']\n",
      "Liberal Percentage:  5 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('roe', 0.429), ('wade', 0.197), ('v', 0.0)]\n",
      "Conservative Words:  [('thank', -0.15), ('is', -0.069), ('god', -0.056)]\n",
      "Original Liberal Words:  ['roe', 'wade', 'v']\n",
      "Original Conservative Words:  ['thank', 'is', 'god']\n",
      "Liberal Percentage:  6 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  []\n",
      "Conservative Words:  []\n",
      "Original Liberal Words:  []\n",
      "Original Conservative Words:  []\n",
      "Liberal Percentage:  7 0.2171458321821546\n",
      "Conservative Percentage:  0.7828541678178453\n",
      "Liberal Words:  [('years', 0.086), ('been', 0.085)]\n",
      "Conservative Words:  [('past', -0.207), ('doing', -0.109)]\n",
      "Original Liberal Words:  ['years', 'been']\n",
      "Original Conservative Words:  ['past', 'doing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get model with vectorizer\n",
    "# with open(\"savedModels/svmModel.pkl\", \"rb\") as model_file:\n",
    "with open(\"savedModels/politicalCCModel.pkl\", \"rb\") as model_file:\n",
    "    model, vectorizer = pickle.load(model_file)\n",
    "vectorizedText = vectorizer.transform(text) # CHANGED HERE\n",
    "textsTransformed = pd.DataFrame(\n",
    "    vectorizedText.toarray(), columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "# predict text bias probabilities\n",
    "pred = model.predict_proba(textsTransformed)\n",
    "# get most influential words\n",
    "predict_function = lambda x: model.predict_proba(vectorizer.transform(x))\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    explanation = explainer.explain_instance(\n",
    "        text[i], predict_function, num_features=20\n",
    "    )\n",
    "    top_words_lime = explanation.as_list()\n",
    "    liberalWords = []\n",
    "    conservativeWords = []\n",
    "    for word, score in top_words_lime:\n",
    "        if score > 0:\n",
    "            liberalWords.append((word, round(score, 3)))\n",
    "        else:\n",
    "            conservativeWords.append((word, round(score, 3)))\n",
    "\n",
    "    # make the amount of liberal and conservative words equal\n",
    "    liberalWords = liberalWords[:10]\n",
    "    conservativeWords = conservativeWords[:10]\n",
    "    if len(liberalWords) != len(conservativeWords):\n",
    "        liberalWords = liberalWords[\n",
    "            : min(len(liberalWords), len(conservativeWords))\n",
    "        ]\n",
    "        conservativeWords = conservativeWords[\n",
    "            : min(len(liberalWords), len(conservativeWords))\n",
    "        ]\n",
    "\n",
    "    # get original words from stemmed words (map)\n",
    "    liberalStemmedWords = [stemmer.stem(word) for word, score in liberalWords]\n",
    "    conservativeStemmedWords = [\n",
    "        stemmer.stem(word) for word, score in conservativeWords\n",
    "    ]\n",
    "    originalLiberalWords = []\n",
    "    originalConservativeWords = []\n",
    "    for stemmedWord in liberalStemmedWords:\n",
    "        for token in text[i].split():\n",
    "            if stemmer.stem(token) == stemmedWord:\n",
    "                originalLiberalWords.append(token)\n",
    "                break\n",
    "    for stemmedWord in conservativeStemmedWords:\n",
    "        for token in text[i].split():\n",
    "            if stemmer.stem(token) == stemmedWord:\n",
    "                originalConservativeWords.append(token)\n",
    "                break\n",
    "\n",
    "    print(\"Liberal Percentage: \", pred[0][1])\n",
    "    print(\"Conservative Percentage: \", pred[0][0])\n",
    "    print(\"Liberal Words: \", liberalWords)\n",
    "    print(\"Conservative Words: \", conservativeWords)\n",
    "    print(\"Original Liberal Words: \", originalLiberalWords)\n",
    "    print(\"Original Conservative Words: \", originalConservativeWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.7696655675930287\n",
      "Confusion matrix Random Forest:\n",
      " [[2024  297]\n",
      " [ 681 1244]]\n",
      "\n",
      "Accuracy SVC: 0.7618935468676401\n",
      "Confusion matrix SVC:\n",
      " [[1835  486]\n",
      " [ 525 1400]]\n",
      "\n",
      "Accuracy Calib. Classifier: 0.7616580310880829\n",
      "Confusion matrix Calib. Classifier:\n",
      " [[1828  493]\n",
      " [ 519 1406]]\n",
      "\n",
      "Accuracy Stochastic Gradient Descent: 0.7633066415449835\n",
      "Confusion matrix Stochastic Gradient Descent:\n",
      " [[1908  413]\n",
      " [ 592 1333]]\n"
     ]
    }
   ],
   "source": [
    "accuracyrf = accuracy_score(y_test, predrf)\n",
    "accuracySVC = accuracy_score(y_test, predSVC)\n",
    "accuracyCC = accuracy_score(y_test, predCC)\n",
    "accuracySGD = accuracy_score(y_test, predSGD)\n",
    "# accuracyPip = accuracy_score(y_test, predPip)\n",
    "# accuracyEoE = accuracy_score(y_test, predEoE)\n",
    "\n",
    "cmrf = confusion_matrix(y_test, predrf)\n",
    "cmSVC = confusion_matrix(y_test, predSVC)\n",
    "cmCC = confusion_matrix(y_test, predCC)\n",
    "cmSGD = confusion_matrix(y_test, predSGD)\n",
    "# cmPip = confusion_matrix(y_test, predPip)\n",
    "# cmEoE = confusion_matrix(y_test, predEoE)\n",
    "\n",
    "print(\"Accuracy Random Forest:\", accuracyrf)\n",
    "print(\"Confusion matrix Random Forest:\\n\", cmrf)\n",
    "print(\"\\nAccuracy SVC:\", accuracySVC)\n",
    "print(\"Confusion matrix SVC:\\n\", cmSVC)\n",
    "print(\"\\nAccuracy Calib. Classifier:\", accuracyCC)\n",
    "print(\"Confusion matrix Calib. Classifier:\\n\", cmCC)\n",
    "print(\"\\nAccuracy Stochastic Gradient Descent:\", accuracySGD)\n",
    "print(\"Confusion matrix Stochastic Gradient Descent:\\n\", cmSGD)\n",
    "# print(\"\\nAccuracy Pipeline:\", accuracyPip)\n",
    "# print(\"Confusion matrix Pipeline:\\n\", cmPip)\n",
    "# print(\"\\nAccuracy Ensemble of Ensembles:\", accuracyEoE)\n",
    "# print(\"Confusion matrix Ensemble of Ensembles:\\n\", cmEoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Random Forest: 0.375\n",
      "Confusion matrix Random Forest (picks liberal all the time):\n",
      " [[3 0]\n",
      " [5 0]]\n",
      "\n",
      "Accuracy Calib. Classifier: 0.625\n",
      "Confusion matrix Calib. Classifier:\n",
      " [[3 0]\n",
      " [3 2]]\n",
      "\n",
      "Accuracy Stochastic Gradient Descent: 0.5\n",
      "Confusion matrix Stochastic Gradient Descent:\n",
      " [[3 0]\n",
      " [4 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "X_samples= ['''Liberals know what's up''',\n",
    "            '''Abortion should be illegal.''',\n",
    "            '''Trump for the win''',\n",
    "            '''no more student debt yessss. Thanks biden''',\n",
    "            '''even if Trump is old, biden is too old''',\n",
    "            '''thank god roe v wade is gone''',\n",
    "            '''MAGA. MAGA. MAGA''',\n",
    "            '''biden hasn't been doing too bad the past couple of years''']\n",
    "\n",
    "y_cgpt = [1, 0, 0, 1, 0, 0, 0, 1] # 0 is conservative (similar to female); 1 is liberal (similar to male)\n",
    "\n",
    "cv_cgpt = vectorizer.transform(X_samples)\n",
    "pd_cgpt = pd.DataFrame(data = cv_cgpt.toarray())\n",
    "X_cgpt = pd_cgpt.iloc[:,:].values\n",
    "\n",
    "predrfGPT = modelrf.predict(X_cgpt)\n",
    "predCCGPT = modelCC.predict(X_cgpt)\n",
    "predSGDGPT = modelSGD.predict(X_cgpt)\n",
    "\n",
    "# report performance\n",
    "print(\"\\nAccuracy Random Forest:\", accuracy_score(y_cgpt, predrfGPT))\n",
    "print(\"Confusion matrix Random Forest (picks liberal all the time):\\n\", confusion_matrix(y_cgpt, predrfGPT))\n",
    "print(\"\\nAccuracy Calib. Classifier:\", accuracy_score(y_cgpt, predCCGPT))\n",
    "print(\"Confusion matrix Calib. Classifier:\\n\", confusion_matrix(y_cgpt, predCCGPT))\n",
    "print(\"\\nAccuracy Stochastic Gradient Descent:\", accuracy_score(y_cgpt, predSGDGPT))\n",
    "print(\"Confusion matrix Stochastic Gradient Descent:\\n\", confusion_matrix(y_cgpt, predSGDGPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d31fc6a8204de3b4072b5546421e13825b968bc2d7431df16c61b9e7419f929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
