{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# # Preprocessing functions\n",
    "# add space before punctuations\n",
    "\n",
    "app = Flask(__name__)\n",
    "explainer = LimeTextExplainer(class_names=['female', 'male'])\n",
    "stemmer = PorterStemmer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# remove gendered pronounds, names, stop words, and apply stemming\n",
    "def removeUnnecessaryWords(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    result = \" \".join([\n",
    "        \"\" if (\n",
    "            token.pos_ == \"PRON\" and token.lemma_ not in [\"I\", \"you\"]\n",
    "        ) or (\n",
    "            token.ent_type_ == \"PERSON\" or token.text.lower() in [\"woman\", \"women\", \"man\", \"men\", \"he\", \"she\", \"him\", \"her\"]\n",
    "        ) or (\n",
    "            token.text.lower() in STOP_WORDS\n",
    "        ) else stemmer.stem(token.lemma_) for token in doc])\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = pd.read_csv('../datasets/BUG/balanced_BUG.csv')\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "# get samples with only neutral or stereotype sentence\n",
    "train = train[train['stereotype'].isin([0, 1])]\n",
    "test = test[test['stereotype'].isin([0, 1])]\n",
    "\n",
    "# apply preprocessing\n",
    "train['sentence_text'] = train['sentence_text'].apply(removeUnnecessaryWords)\n",
    "test['sentence_text'] = test['sentence_text'].apply(removeUnnecessaryWords)\n",
    "\n",
    "countV = TfidfVectorizer()\n",
    "trainTexts = countV.fit_transform(train['sentence_text'])\n",
    "testTexts = countV.transform(test['sentence_text'])\n",
    "\n",
    "X_train = pd.DataFrame(trainTexts.toarray(), columns=countV.get_feature_names_out())\n",
    "X_test = pd.DataFrame(testTexts.toarray(), columns=countV.get_feature_names_out())\n",
    "y_train = train['predicted gender']\n",
    "y_test = test['predicted gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that utilizes cross validation to test accuracy of model\n",
    "def evaluate_model(model):\n",
    "    # cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "    scores = cross_val_score(model, X_test, y_test, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# Function that utilizes cross validation to test accuracy of model\n",
    "def evaluate_model_f1(model):\n",
    "    # cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "    scores = cross_val_score(model, X_test, y_test, cv=cv, scoring='f1_macro', n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9282\n",
      "F1-score: 0.9281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = evaluate_model(rf)\n",
    "scoresf1 = evaluate_model_f1(rf)\n",
    "print('Accuracy: {:.4f}'.format(scores.mean()))\n",
    "print('F1-score: {:.4f}'.format(scoresf1.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of Ensembles (EoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9052\n",
      "F1-score: 0.9052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_features=1, random_state=0)\n",
    "clf2 = BaggingClassifier(max_features=4, random_state=0)\n",
    "clf3 = RandomForestClassifier(max_features=1, random_state=0)\n",
    "clf4 = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "eclf1 = VotingClassifier(estimators=[('dt', clf1), ('bdt', clf2), ('rf', clf3), ('ab', clf4)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "pred = eclf1.predict(X_test)\n",
    "print('Accuracy: {:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "print('F1-score: {:.4f}'.format(f1_score(y_test, pred, average='weighted')))\n",
    "\n",
    "with open('../savedModels/ensembleOfEnsembles.pkl', 'wb') as model_file:\n",
    "    pickle.dump((eclf1, countV), model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.810 (0.028)\n",
      "F1-score: 0.802 (0.030)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
    "model1 = Pipeline(steps=steps)\n",
    "\n",
    "# evaluate model\n",
    "n_scores1 = evaluate_model(model1)\n",
    "n_scores1f1 = evaluate_model_f1(model1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores1), std(n_scores1)))\n",
    "print('F1-score: %.3f (%.3f)' % (mean(n_scores1f1), std(n_scores1f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 754, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, error_score)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n    scores = scorer(estimator, X_test, y_test)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 144, in __call__\n    raise e\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n    score = scorer._score(\n            ^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n    result, _ = _get_response_values(\n                ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n    y_pred = prediction_method(X)\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n    ArgKmin.is_usable_for(X, Y, metric)\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n         ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n    return hasattr(X, \"flags\") and X.flags.c_contiguous\n                                   ^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Flags' object has no attribute 'c_contiguous'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m modelknn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m knn_scores1 \u001b[39m=\u001b[39m evaluate_model(modelknn)\n\u001b[1;32m      8\u001b[0m knn_scores1f1 \u001b[39m=\u001b[39m evaluate_model_f1(modelknn)\n\u001b[1;32m     10\u001b[0m \u001b[39m# report performance\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_model\u001b[39m(model):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     scores \u001b[39m=\u001b[39m cross_val_score(model, X_test, y_test, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Applying k = 3, default Minkowski distance metrics\n",
    "modelknn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# evaluate model\n",
    "knn_scores1 = evaluate_model(modelknn)\n",
    "knn_scores1f1 = evaluate_model_f1(modelknn)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(knn_scores1), std(knn_scores1)))\n",
    "print('F1-score: %.3f (%.3f)' % (mean(knn_scores1f1), std(knn_scores1f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.611 (0.056)\n"
     ]
    }
   ],
   "source": [
    "X_samples= ['''In the bustling halls of his college, a young man navigated the complexities of academia, \n",
    "            friendships, and love, discovering his passion for astronomy while forging lifelong connections \n",
    "            under the starlit campus nights.''',\n",
    "            '''At the forefront of environmental activism, a passionate college girl spearheaded a movement \n",
    "            for sustainability, rallying her peers to embrace eco-friendly practices and leaving an enduring \n",
    "            green legacy on the university campus''',\n",
    "            '''Amid the chaos of exams and late-night study sessions, a college guy found unexpected \n",
    "            inspiration in a quirky poetry club, where he unearthed his hidden talent for weaving words \n",
    "            and discovered the transformative power of self-expression.''',\n",
    "            '''Juggling lectures, part-time work, and a secret flair for dance, a college guy discovered \n",
    "            the joy of breaking societal expectations and embracing his love for rhythm in the unlikeliest places''',\n",
    "            '''Fueled by caffeine and dreams, a college male embarked on a coding marathon, racing against deadlines \n",
    "            and debugging errors, only to realize that the true beauty lay not in perfection but in the process of \n",
    "            creation''',\n",
    "            '''Navigating the complexities of relationships and self-discovery, a young woman in college learned \n",
    "            the art of balancing vulnerability and strength, discovering that love was not a distraction but an \n",
    "            integral part of personal growth''',\n",
    "            '''In the heart of campus activism, a socially conscious college guy led a passionate movement, \n",
    "            challenging the status quo and igniting conversations that echoed beyond lecture halls, leaving \n",
    "            an indelible mark on the institution''',\n",
    "            '''Navigating the whirlwind of college relationships, a young man learned the delicate dance of \n",
    "            vulnerability and trust, discovering that love's lessons often unfolded in unexpected moments \n",
    "            of connection and understanding''',\n",
    "            '''Battling imposter syndrome and academic pressures, a college male found solace and empowerment in \n",
    "            a supportive mentorship program, where guidance and camaraderie transformed his doubts into \n",
    "            unwavering self-confidence''',\n",
    "            '''From quiet study sessions to the loud cheers of the basketball court, a college guy embraced \n",
    "            the duality of his passions, discovering that both the pursuit of knowledge and the thrill of \n",
    "            competition were essential components of his identity''',\n",
    "            '''Battling imposter syndrome and academic challenges, a college female sought guidance in a mentorship \n",
    "            program, where the wisdom of experienced women empowered her to overcome obstacles and embrace her own \n",
    "            capabilities''',\n",
    "            '''In the realm of campus journalism, a determined college male delved into investigative reporting, \n",
    "            unearthing hidden truths and exposing corruption, challenging the notion that the pen was not, indeed, \n",
    "            mightier than the sword''',\n",
    "            '''Faced with the crossroads of post-graduation uncertainty, a college guy embarked on a solo \n",
    "            backpacking journey, traversing landscapes both external and internal, finding unexpected clarity \n",
    "            and purpose in the uncharted territories of self-discovery''',\n",
    "            '''Balancing lectures and a part-time job, a college girl discovered her love for urban gardening, \n",
    "            cultivating not just plants but also a sense of tranquility amidst the bustling campus''',\n",
    "            '''Fueled by curiosity and countless cups of tea, a college female delved into the world of \n",
    "            ancient history, unraveling forgotten tales and finding parallels that connected her to the roots of \n",
    "            civilizations''',\n",
    "            '''A tenacious college woman, armed with a camera and a passion for storytelling, joined the ranks of \n",
    "            campus journalism, unearthing hidden narratives and giving voice to the marginalized, proving that \n",
    "            the pursuit of truth could be a powerful force for change''',\n",
    "            '''Confronting post-graduation uncertainties with resilience, a college female embarked on a solo \n",
    "            backpacking adventure, navigating both physical landscapes and the landscapes of her own ambitions, \n",
    "            discovering that the journey of self-discovery knows no gender''',\n",
    "            '''From late-night coding sessions to the spotlight on the theater stage, a college girl embraced the \n",
    "            diversity of her interests, realizing that the fusion of logic and creativity was the key to \n",
    "            unlocking her full potential''']\n",
    "y_cgpt = [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0] # 1 is male; 0 is female\n",
    "\n",
    "cv_cgpt = countV.transform(X_samples)\n",
    "pd_cgpt = pd.DataFrame(data = cv_cgpt.toarray())\n",
    "X_cgpt = pd_cgpt.iloc[:,:].values\n",
    "\n",
    "steps_cgpt = [('pca', PCA(n_components=5)), ('m', LogisticRegression())]\n",
    "model2 = Pipeline(steps=steps_cgpt)\n",
    "\n",
    "cv2 = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "scores2 = cross_val_score(model2, X_cgpt, y_cgpt, cv=cv2, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "scores2f1 = cross_val_score(model2, X_cgpt, y_cgpt, cv=cv2, scoring='f1_macro', n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores2), std(scores2)))\n",
    "print('F1-score: %.3f (%.3f)' % (mean(scores2f1), std(scores2f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = ['''Determined to bridge the gap in STEM fields, a college woman immersed herself in robotics \n",
    "             and artificial intelligence, breaking barriers and inspiring the next generation of female \n",
    "             engineers with her innovative projects and unwavering passion''']\n",
    "\n",
    "cv_test_cgpt = countV.transform(X_samples)\n",
    "# cv_test_cgpt = countV.transform(test_sample)\n",
    "pd_test_cgpt = pd.DataFrame(data = cv_test_cgpt.toarray())\n",
    "test_cgpt = pd_test_cgpt.iloc[:,:].values\n",
    "\n",
    "pd_tr = pd.DataFrame(data = trainTexts.toarray())\n",
    "\n",
    "# add filler columns so that test_cgpt will have the same number of columns as X_train\n",
    "test_cgpt = pd.DataFrame(test_cgpt).reindex(labels=pd_tr.columns,axis=1,fill_value=0)\n",
    "test_cgpt = test_cgpt.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the classifier\n",
    "model2 = model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted PCA: ['male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female']\n",
      "Predicted Random Forest: ['male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'female' 'female' 'female' 'male' 'female'\n",
      " 'female']\n",
      "Expected: [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Testing the classifier\n",
    "pca_cgpt_pred = model2.predict(test_cgpt)\n",
    "rf_cgpt_pred = model3.predict(test_cgpt)\n",
    "\n",
    "expected = y_cgpt   # for X_samples\n",
    "# expected = [0]    # for test_sample\n",
    "\n",
    "print('Predicted PCA:', pca_cgpt_pred)\n",
    "print('Predicted Random Forest:', rf_cgpt_pred)\n",
    "print('Expected:', expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Random Forest: ['male' 'female' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female']\n",
      "Expected: [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/byroncuachin/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "eoe_model_cgpt = eclf1.predict(test_cgpt)\n",
    "\n",
    "print('Predicted Random Forest:', eoe_model_cgpt)\n",
    "print('Expected:', expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d31fc6a8204de3b4072b5546421e13825b968bc2d7431df16c61b9e7419f929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
